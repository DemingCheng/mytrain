{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batchsize\n",
    "显卡占用显存\n",
    "step\n",
    "token生成速度\n",
    "训练时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一篇750词的英文文章中大约含有1000个token。\n",
    "\n",
    "- 超过10倍：批量处理LLM请求带来的吞吐量改善\n",
    "\n",
    "在GPU上运行LLM时往往会有较大延迟。\n",
    "\n",
    "一次请求消耗的时间可能长达5秒，相对于每秒仅能处理0.2个。\n",
    "\n",
    "但如果同时发送两个请求，消耗的时间约为5.2秒。\n",
    "\n",
    "而将25个请求捆绑发出的耗时约为10秒，相对于每秒可处理2.5个请求。\n",
    "\n",
    "- 约1MB：130亿参数模型输出1个token所需的GPU内存\n",
    "\n",
    "内存消耗量与生成token数成正比。\n",
    "\n",
    "512个token（约380个英文单词）需要消耗512MB的空间。\n",
    "\n",
    "- 参数量的2倍：LLM的典型GPU内存需求\n",
    "\n",
    "例如，7B参数量的LLM需要消耗14GB的GPU内存。\n",
    "\n",
    "这是因为大多数时候，每个参数需要16bit浮点空间。\n",
    "\n",
    "通常情况下不需要使用超过16bit的精度，8bit则会显著降低结果精准度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data.txt\n",
    "包含\n",
    "weather 37\n",
    "food 37\n",
    "medicine 38\n",
    "\n",
    "\n",
    "健康管理：包括饮食、运动、睡眠等健康相关的话题。\n",
    "生活咨询：包括天气、交通、旅游等日常生活中的问题。\n",
    "情感陪伴：包括聊天、讲故事、唱歌等陪伴用户度过无聊时光的活动。\n",
    "知识问答：包括科技、文化、历史、艺术等各类知识的问答。\n",
    "技能学习：包括语言学习、编程、手工制作等技能的学习。\n",
    "\n",
    "例如睡眠，如果学习了很多通用的睡眠常识，会不会影响用户问“我的睡眠情况”的回答？这是工程上的问题还是在算法训练，数据制作时考虑？"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
